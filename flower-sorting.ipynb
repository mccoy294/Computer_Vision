{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8caec5e6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-16T05:03:53.002481Z",
     "iopub.status.busy": "2023-07-16T05:03:53.002108Z",
     "iopub.status.idle": "2023-07-16T05:03:53.182784Z",
     "shell.execute_reply": "2023-07-16T05:03:53.181893Z"
    },
    "papermill": {
     "duration": 0.18947,
     "end_time": "2023-07-16T05:03:53.184870",
     "exception": false,
     "start_time": "2023-07-16T05:03:52.995400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of directories: 6\n",
      "Total number of files: 815\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "total_files = 0\n",
    "total_direct = 0\n",
    "try:\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            total_files +=1\n",
    "\n",
    "        total_direct +=1\n",
    "    print(\"Total number of directories: \"+ str(total_direct))\n",
    "    print(\"Total number of files: \"+str(total_files))\n",
    "except:\n",
    "    print(\"An error occured walking through the OS Directories\")\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c4999e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T05:03:53.194790Z",
     "iopub.status.busy": "2023-07-16T05:03:53.194470Z",
     "iopub.status.idle": "2023-07-16T05:04:02.622406Z",
     "shell.execute_reply": "2023-07-16T05:04:02.621285Z"
    },
    "papermill": {
     "duration": 9.43605,
     "end_time": "2023-07-16T05:04:02.625318",
     "exception": false,
     "start_time": "2023-07-16T05:03:53.189268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "#Required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from keras import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b827c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T05:04:02.636981Z",
     "iopub.status.busy": "2023-07-16T05:04:02.635615Z",
     "iopub.status.idle": "2023-07-16T05:04:02.645318Z",
     "shell.execute_reply": "2023-07-16T05:04:02.644273Z"
    },
    "papermill": {
     "duration": 0.018435,
     "end_time": "2023-07-16T05:04:02.648233",
     "exception": false,
     "start_time": "2023-07-16T05:04:02.629798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Structure of the training model:\\n--- Where to find all the data for training and testing\\nX_train_data_path = \"/input_file/training_data/images\"\\nX_test_data_path = \"/input_file/test_data/images\"\\n\\n--- Storing the data for training from the above paths\\nx_train = []\\n\\n--- Iterate through the folder and pull out the files that end with \".jpeg\" and add them to the training list.\\nfor filename in os.listdir(x_train_path):\\n    if filename.endswith(\".jpeg\"):\\n        img = image.load_img(x_train_path+filename, target_size=(128, 128))\\n        x_train.append(image.img_to_array(img))\\nx_train = np.array(x_train)\\n\\n--- Storing the data for testing from the above paths\\nx_test = []\\n\\n---Iterate through the folder and pull out the files that end with \".jpeg\" and add them to the test list.\\nfor filename in os.listdir(x_test_path):\\n    if filename.endswith(\".jpeg\"):\\n        img = image.load_img(x_test_path+filename, target_size=(128, 128))\\n        x_test.append(image.img_to_array(img))\\nx_test = np.array(x_test)\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Structure of the training model:\n",
    "--- Where to find all the data for training and testing\n",
    "X_train_data_path = \"/input_file/training_data/images\"\n",
    "X_test_data_path = \"/input_file/test_data/images\"\n",
    "\n",
    "--- Storing the data for training from the above paths\n",
    "x_train = []\n",
    "\n",
    "--- Iterate through the folder and pull out the files that end with \".jpeg\" and add them to the training list.\n",
    "for filename in os.listdir(x_train_path):\n",
    "    if filename.endswith(\".jpeg\"):\n",
    "        img = image.load_img(x_train_path+filename, target_size=(128, 128))\n",
    "        x_train.append(image.img_to_array(img))\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "--- Storing the data for testing from the above paths\n",
    "x_test = []\n",
    "\n",
    "---Iterate through the folder and pull out the files that end with \".jpeg\" and add them to the test list.\n",
    "for filename in os.listdir(x_test_path):\n",
    "    if filename.endswith(\".jpeg\"):\n",
    "        img = image.load_img(x_test_path+filename, target_size=(128, 128))\n",
    "        x_test.append(image.img_to_array(img))\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11c1abd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T05:04:02.658966Z",
     "iopub.status.busy": "2023-07-16T05:04:02.658629Z",
     "iopub.status.idle": "2023-07-16T05:04:08.874458Z",
     "shell.execute_reply": "2023-07-16T05:04:08.873487Z"
    },
    "papermill": {
     "duration": 6.224174,
     "end_time": "2023-07-16T05:04:08.876963",
     "exception": false,
     "start_time": "2023-07-16T05:04:02.652789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Add the path for the images\n",
    "X_train_data_path = \"/kaggle/input/flower-color-images/flowers/flowers/\"\n",
    "X_test_data_path = \"/kaggle/input/flower-color-images/flower_images/flower_images/\"\n",
    "\n",
    "\n",
    "#Storing the data for training from the above paths\n",
    "x_train = []\n",
    "\n",
    "#Add each file to the training set that matches the the end extension\n",
    "for filename in os.listdir(X_train_data_path):\n",
    "    if filename.endswith(\".png\"):\n",
    "        img = image.load_img(X_train_data_path+filename, target_size=(224, 224))\n",
    "        x_train.append(image.img_to_array(img))\n",
    "appendx_train = np.array(x_train)\n",
    "\n",
    "#Storing the data for testing from the above paths\n",
    "x_test = []\n",
    "\n",
    "#Add each file to the testing set that matches the the end extension\n",
    "for filename in os.listdir(X_test_data_path):\n",
    "    if filename.endswith(\".png\"):\n",
    "        img = image.load_img(X_test_data_path+filename, target_size=(224, 224))\n",
    "        x_test.append(image.img_to_array(img))\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b805ab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T05:04:08.888238Z",
     "iopub.status.busy": "2023-07-16T05:04:08.887509Z",
     "iopub.status.idle": "2023-07-16T05:04:09.135309Z",
     "shell.execute_reply": "2023-07-16T05:04:09.134439Z"
    },
    "papermill": {
     "duration": 0.256432,
     "end_time": "2023-07-16T05:04:09.138156",
     "exception": false,
     "start_time": "2023-07-16T05:04:08.881724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(603, 224, 224, 3)\n",
      "(210, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#Convert the arrays to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "#Test the shape of the data\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ddb902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T05:04:09.153473Z",
     "iopub.status.busy": "2023-07-16T05:04:09.152522Z",
     "iopub.status.idle": "2023-07-16T05:04:09.667561Z",
     "shell.execute_reply": "2023-07-16T05:04:09.666401Z"
    },
    "papermill": {
     "duration": 0.525677,
     "end_time": "2023-07-16T05:04:09.670508",
     "exception": false,
     "start_time": "2023-07-16T05:04:09.144831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reset the tensorflow graph so the resulting code that follows is not impacted\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#Setting the training sizes for the convolutions\n",
    "input_img = Input(shape=(224, 224, 3))  \n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)  \n",
    "x = MaxPooling2D((2, 2))(x)  \n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)  \n",
    "\n",
    "#Compress the image\n",
    "encoded = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "#Transpose the convolutions while encoded\n",
    "x = Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(encoded)  \n",
    "x = UpSampling2D((2, 2))(x)  \n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu',padding='same')(x) \n",
    "x = UpSampling2D((2, 2))(x)  \n",
    "\n",
    "decoded = Conv2D(3, (3, 3), padding='same')(x)  \n",
    "\n",
    "autoencoder = Model(input_img, decoded)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06966a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T05:04:09.683151Z",
     "iopub.status.busy": "2023-07-16T05:04:09.681993Z",
     "iopub.status.idle": "2023-07-16T05:04:09.702945Z",
     "shell.execute_reply": "2023-07-16T05:04:09.701591Z"
    },
    "papermill": {
     "duration": 0.029936,
     "end_time": "2023-07-16T05:04:09.705713",
     "exception": false,
     "start_time": "2023-07-16T05:04:09.675777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Instantiate the model and train using: Adam optimizer, MSE for loss function, and test based on accuracy\n",
    "autoencoder.compile(optimizer='adam', loss='mse' , metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e935f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T05:04:09.718637Z",
     "iopub.status.busy": "2023-07-16T05:04:09.716733Z",
     "iopub.status.idle": "2023-07-16T05:04:09.754208Z",
     "shell.execute_reply": "2023-07-16T05:04:09.753304Z"
    },
    "papermill": {
     "duration": 0.065146,
     "end_time": "2023-07-16T05:04:09.775769",
     "exception": false,
     "start_time": "2023-07-16T05:04:09.710623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 16)      4624      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 56, 56, 16)       2320      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 112, 112, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 112, 112, 32)     4640      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 224, 224, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 224, 224, 3)       867       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,347\n",
      "Trainable params: 13,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd45d1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T05:04:09.794742Z",
     "iopub.status.busy": "2023-07-16T05:04:09.793840Z",
     "iopub.status.idle": "2023-07-16T05:22:33.848880Z",
     "shell.execute_reply": "2023-07-16T05:22:33.847593Z"
    },
    "papermill": {
     "duration": 1104.431608,
     "end_time": "2023-07-16T05:22:34.215233",
     "exception": false,
     "start_time": "2023-07-16T05:04:09.783625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "302/302 [==============================] - 82s 265ms/step - loss: 784.0908 - accuracy: 0.7205 - val_loss: 322.7703 - val_accuracy: 0.7914\n",
      "Epoch 2/13\n",
      "302/302 [==============================] - 80s 265ms/step - loss: 289.8833 - accuracy: 0.8056 - val_loss: 225.0017 - val_accuracy: 0.8243\n",
      "Epoch 3/13\n",
      "302/302 [==============================] - 80s 265ms/step - loss: 237.2396 - accuracy: 0.8214 - val_loss: 222.1370 - val_accuracy: 0.8374\n",
      "Epoch 4/13\n",
      "302/302 [==============================] - 81s 268ms/step - loss: 218.2436 - accuracy: 0.8322 - val_loss: 256.5957 - val_accuracy: 0.8256\n",
      "Epoch 5/13\n",
      "302/302 [==============================] - 80s 265ms/step - loss: 216.5189 - accuracy: 0.8316 - val_loss: 166.1437 - val_accuracy: 0.8442\n",
      "Epoch 6/13\n",
      "302/302 [==============================] - 82s 270ms/step - loss: 201.3085 - accuracy: 0.8320 - val_loss: 162.4888 - val_accuracy: 0.8513\n",
      "Epoch 7/13\n",
      "302/302 [==============================] - 81s 268ms/step - loss: 193.2488 - accuracy: 0.8421 - val_loss: 161.4300 - val_accuracy: 0.8392\n",
      "Epoch 8/13\n",
      "302/302 [==============================] - 81s 268ms/step - loss: 185.0074 - accuracy: 0.8358 - val_loss: 150.4031 - val_accuracy: 0.8544\n",
      "Epoch 9/13\n",
      "302/302 [==============================] - 79s 263ms/step - loss: 175.3170 - accuracy: 0.8404 - val_loss: 147.5539 - val_accuracy: 0.8451\n",
      "Epoch 10/13\n",
      "302/302 [==============================] - 80s 267ms/step - loss: 192.2933 - accuracy: 0.8299 - val_loss: 143.0280 - val_accuracy: 0.8589\n",
      "Epoch 11/13\n",
      "302/302 [==============================] - 80s 265ms/step - loss: 176.2029 - accuracy: 0.8465 - val_loss: 173.0650 - val_accuracy: 0.8391\n",
      "Epoch 12/13\n",
      "302/302 [==============================] - 80s 264ms/step - loss: 173.6327 - accuracy: 0.8407 - val_loss: 134.2330 - val_accuracy: 0.8576\n",
      "Epoch 13/13\n",
      "302/302 [==============================] - 80s 265ms/step - loss: 163.9707 - accuracy: 0.8441 - val_loss: 134.2208 - val_accuracy: 0.8618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe539f0e5c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with the training data, for 13 epochs and then validate using the assigned test data\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=13,\n",
    "                batch_size=2,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6af84e",
   "metadata": {
    "papermill": {
     "duration": 0.391843,
     "end_time": "2023-07-16T05:22:34.974721",
     "exception": false,
     "start_time": "2023-07-16T05:22:34.582878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1135.27842,
   "end_time": "2023-07-16T05:22:37.474111",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-16T05:03:42.195691",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
